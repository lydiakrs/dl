{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3b78f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\kevintatibouet\\anaconda3\\lib\\site-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\kevintatibouet\\anaconda3\\lib\\site-packages (from opencv-python) (1.20.1)\n",
      "Requirement already satisfied: imutils in c:\\users\\kevintatibouet\\anaconda3\\lib\\site-packages (0.5.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install imutils\n",
    "!pip install pyshine \n",
    "!pip install keras\n",
    "!pip install sounddevice\n",
    "!pip install flask\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d7cd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning! No module named 'soundfile'\n",
      "opencv_frame_0.png written!\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://10.100.21.50:9999/ (Press CTRL+C to quit)\n",
      "10.100.21.50 - - [13/Jun/2022 16:51:35] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10.100.21.50 - - [13/Jun/2022 16:51:37] \"\u001b[37mGET /pred HTTP/1.1\u001b[0m\" 200 -\n",
      "10.100.21.50 - - [13/Jun/2022 16:51:55] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10.100.21.50 - - [13/Jun/2022 16:51:57] \"\u001b[37mGET /pred HTTP/1.1\u001b[0m\" 200 -\n",
      "10.100.21.50 - - [13/Jun/2022 16:51:57] \"\u001b[37mGET /static/opencv_frame_0.png HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model2_save = tf.keras.models.load_model('model2.h5')\n",
    "model2_e_save = tf.keras.models.load_model('model2_e.h5')\n",
    "model2_a_save = tf.keras.models.load_model('model2_a.h5')\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from flask import Flask, render_template,request,Response\n",
    "import cv2,imutils,time\n",
    "import pyshine as ps\n",
    "\n",
    "app = Flask(__name__)\n",
    "@app.route('/')\n",
    "def anyname():\n",
    "       return render_template('index.html')\n",
    "@app.route('/cam')\n",
    "def camtest():\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    cpt = 0\n",
    "    while True:\n",
    "        check, frame = cam.read()\n",
    "        cv2.imshow('video', frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27:\n",
    "            cam.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "        elif key == 32:\n",
    "            img_name = \"opencv_frame_{}.png\".format(cpt)\n",
    "            cv2.imwrite(\"static/\"+img_name, frame)\n",
    "            print(\"{} written!\".format(img_name))\n",
    "            cpt += 1\n",
    "camtest()\n",
    "\n",
    "@app.route('/pred')    \n",
    "def pred():\n",
    "    img_source=r\"opencv_frame_0.png\"\n",
    "    img = cv2.imread(r\"C:\\Users\\KevinTATIBOUET\\Downloads\\test-main\\test-main\\static\\opencv_frame_0.png\")\n",
    "    img = cv2.resize(img,(48,48))\n",
    "    #img_ = cv2.imread(r\"C:\\Users\\KevinTATIBOUET\\Downloads\\test-main\\test-main\\static\\opencv_frame_0.png\")\n",
    "    #frame = cv2.imencode('.jpg', img_)[1].tobytes()\n",
    "    pic_ = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    pic_= np.reshape(pic_,(1,2304))\n",
    "    pic_= pic_ / 255\n",
    "    picture_predict_gender = np.argmax(model2_save.predict(pic_),axis=1)\n",
    "    picture_predict_ethnicity = np.argmax(model2_e_save.predict(pic_),axis=1)\n",
    "    picture_predict_age = np.argmax(model2_a_save.predict(pic_),axis=1)\n",
    "    GENDERS = { 0: \"Male\", 1: \"Female\" }\n",
    "    ETHNICITIES = { 0: \"White\", 1: \"Black\", 2: \"Asian\", 3: \"Indian\", 4: \"Hispanic\" }\n",
    "    AGE ={0: \"Enfant\", 1: \"Jeune\", 2: \"Adulte\", 3: \"Vieux\"}\n",
    "    return render_template(\"prediction.html\", **{\"greeting\":[AGE.get(picture_predict_age[0]),ETHNICITIES.get(picture_predict_ethnicity[0]),GENDERS.get(picture_predict_gender[0])] })\n",
    "    \n",
    "#pred()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host=\"10.100.21.50\",debug=False,port=9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76239663",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
